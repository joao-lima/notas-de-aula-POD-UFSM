%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Classificação de dados}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Os algoritmos deste capítulo resolvem o {\bf problema de ordenação}:
\begin{itemize}
\item {\bf Entrada}: uma sequência de $n$ números $\langle a_1, a_2, ..., a_n \rangle$.

\item {\bf Saída}:  Uma permutação $\langle {a'}_1, {a'}_2, ..., {a'}_n \rangle$ da
entrada tal que ${a'}_1 \leq {a'}_2 \leq ... \leq {a'}_n$.
\end{itemize}
Ordenação pode ser usado em diversos outros algoritmos.
Ela pode ser necessária devido a requisitos do usuário, ou para a otimização de pesquisa 
como na pesquisa binária.

Em geral os dados são mantidos em um vetor onde cada objeto possui um
atributo \textbf{chave} que deve ser mantido ordenado.
Para fins de exemplo, utiliza-se números inteiros como elementos.

Um algoritmo de ordenação possui duas características principais:
\begin{itemize}
\item {\bf Estabilidade} -- relativo a manutenção da ordem original dos itens 
com chaves iguais.
	\begin{itemize}
	\item Um algoritmo de ordenação é {\bf estável} se a ordem relativa dos itens
		com chaves iguais não se altera durante a ordenação.
	\end{itemize}
\item {\bf Uso de memória} -- quanto ao uso de memória pelo algoritmo.
	\begin{itemize}
	\item {\bf Com cópia de dados} -- utiliza um vetor temporário para realizar a ordenação. As trocas são feitas entre o vetor original e o temporário.
	\item {\bf In-place} -- as trocas são feitas dentro do próprio vetor original.
	\end{itemize}
\end{itemize}

O critério de avaliação, sendo $n$ o número de registros, pode ser por:
\begin{itemize}
\item $C(n)$ -- número de comparações.
\item $M(n)$ -- número de movimentações de elementos.
\end{itemize}
Em grande parte dos casos, nos concentramos no número de comparações.

Os métodos de ordenação podem ser {\bf interno} (em memória primária) ou {\bf externo} (em memória secundária).
Na {\bf interna} o arquivo de entrada cabe todo na memória principal, enquanto
que na {\bf externa} o arquivo não cabe na memória principal. 

A maioria dos métodos é baseada em {\bf comparações} de chaves.
Porém, existem outros métodos que utilizam o principio da {\bf distribuição}. 
Um exemplo é ordenar um baralho com 52 cartas na ordem numérica e ordem de naipes.
O algoritmo seria:
\begin{enumerate}
\item Distribuir cartas em treze montes: ases, dois, três, ...., reis.
\item Coletar os montes na ordem especificada.
\item Distribuir novamente as cartas em quatro montes: paus, ouros, copas e espadas.
\item Coletar os montes na ordem especificada.
\end{enumerate}
Alguns desses métodos são o {\bf radixsort} e o {\bf bucketsort}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Classificação em memória primária}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Podem ser classificados como:
\begin{itemize}
\item {\bf Métodos simples} -- adequado para vetores pequenos, requerem $O(n^2)$ comparações.
Ex.: bolha, inserção, seleção, shellsort.
\item {\bf Métodos eficientes} -- adequados para vetores grandes, requerem $O(n \log n)$ comparações.
Ex.: quicksort, mergesort, heapsort.
\item {\bf Métodos mais eficientes} -- requerem $O(n)$ atribuições. Ex.: radixsort.
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Bolha (\emph{bubble sort})}

O bubblesort ordena os elementos ao colocar o maior sempre no fim do vetor.
O algoritmo é ilustrado na figura~\ref{aula03:algo:bubblesort}.
\begin{figure}[!htb]
\centering
\begin{framed}
\begin{lstlisting}
void Bubblesort( int *A, int n ){
	int i;
	bool trocado;
	do{
		trocado = false;
		for( i = 1; i < n; i++){
			if( A[i-1] > A[i] ){
				troca( A[i-1], A[i] );
				trocado = true;
			}
		}
	} while(trocado);
}
\end{lstlisting}
\end{framed}
\caption{Algoritmo do bubblesort.}
\label{aula03:algo:bubblesort}
\end{figure}

\todo[inline]{Exemplo com $4, 9, 2, 1, 5$.}

O número de comparações é $(n-1)+(n-2)+....+2+1$ com complexidade (para pior caso)
\begin{equation*}
C(n) = \sum_{k=1}^{n-1} i = \frac{n(n-1)}{2} = O(n^2).
\end{equation*}

As principais vantagens:
\begin{itemize}
\item Algoritmo simples.
\item Algoritmo estável.
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Seleção (\emph{selection sort})}

O selectionsort coloca o menor elemento sempre no começo do vetor.
O algoritmo é ilustrado na figura~\ref{aula03:algo:selection}.
\begin{figure}[!htb]
\centering
\begin{framed}
\begin{lstlisting}
void Selecao( int *A, int n ){
	int i, j, min;
	for( i = 0; i < n; i++){
		min = i;
		for(j= i+1; j < n; j++)
			if( A[j] < A[min] )
				min = j;
		troca( A[min], A[i] );
	}
}
\end{lstlisting}
\end{framed}
\caption{Algoritmo de ordenação por seleção.}
\label{aula03:algo:selection}
\end{figure}

\todo[inline]{Exemplo com $4, 9, 2, 1, 5$.}

O número de comparações é $(n-1)+(n-2)+....+2+1$ com complexidade (qualquer caso)
\begin{equation*}
C(n) = \sum_{k=1}^{n-1} i = \frac{n(n-1)}{2} = O(n^2).
\end{equation*}

Vantagens:
\begin{itemize}
\item custo linear para movimentações.
\item interessante para vetores pequenos.
\end{itemize}
Desvantagens:
\begin{itemize}
\item vetor ordenado não ajuda, pois o custo continua quadrático.
\item algoritmo {\bf não é estável}.
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Inserção (\emph{insertion sort})}

A figura~\ref{aula02:algo:insertion} da seção~\ref{aula02:sec:insertion} ilustra
o algoritmo.
%
O número de comparações é $(n-1)+(n-2)+....+2+1$ no pior caso (ordem reversa), com complexidade
\begin{equation*}
C(n) = \sum_{k=1}^{n-1} i = \frac{n(n-1)}{2} = O(n^2).
\end{equation*}
Por outro lado, o número de comparações no melhor caso (vetor ordenado) é 
$1 + 1 + 1 + 1+ .... + 1 = n-1$ com complexidade
\begin{equation*}
C(n) = n - 1  = O(n).
\end{equation*}

\todo[inline]{Exemplo com $4, 9, 2, 1, 5$.}

Vantagens:
\begin{itemize}
\item ideal quando o vetor está ``quase'' ordenado.
\item ordenação estável.
\end{itemize}
Desvantagens:
\begin{itemize}
\item custo médio é quadratico.
\item alto custo para inserir elemento na posição correta.
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Shellsort}

Proposto por Shell em 1959, o algoritmo é uma extensão do insertion sort.
Ele é eficiente quando a entrada está parcialmente ordenado.
Porém, ele é  ineficiente no caso geral pois troca os valores apenas uma posição por vez.

A proposta geral do shellsort é trocar elementos de posições distantes para vetores muito
desordenados, e trocar elementos próximos para entradas parcialmente ordenados.
O algoritmo é ilustrado na figura~\ref{aula03:algo:shellsort}.
Quando $h = 1$ shellsort corresponde ao algoritmo de inserção.
\begin{figure}[!htb]
\centering
\begin{framed}
\begin{lstlisting}
void Shellsort( int *A, int n ){
	int i, j;
	int h = 1;
	while( h < n/3 )
		h = 3*h + 1;
	while( h >= 1 ) {
		for( i = h; i < n; i++ ){
			for( j = i; j >= h && A[j] < A[j-h]; j -= h )
				troca( A[j], A[j-h] );
		}
		h = h/3;
	}
}
\end{lstlisting}
\end{framed}
\caption{Algoritmo de ordenação Shellsort.}
\label{aula03:algo:shellsort}
\end{figure}

\todo[inline]{Exemplo com $4, 9, 2, 1, 5$, para $i= 3$, $i = 2$, e $i = 1$.}

A eficiência depende do intervalo (gap) usado. Exemplos:
\begin{itemize}
\item $gap = \frac{n}{2^k} = \frac{n}{2}, \frac{n}{4}, ...., 1 = O(n^2)$ .
\item $gap = 2^k - 1 = 1,3,7,15,31,.... = O(n^{\frac{3}{2}})$.
\end{itemize}

Vantagens:
\begin{itemize}
\item podem ser mais eficiente que os demais algoritmos de ordem quadrática.
\end{itemize}
Desvantagens:
\begin{itemize}
\item {\bf não é estável}.
\end{itemize}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Comparação dos métodos simples}

A tabela~\ref{aula03:tab:caso01} sumariza os métodos simples e suas complexidades.
%
\begin{table}[!ht]
\centering
\begin{tabular}{lccccc}
\hline
          & Melhor caso & Caso médio & Pior caso & Memória & Estável \\ \hline
Bubble    & $O(n)$ & $O(n^2)$ & $O(n^2)$ & $1$ & sim \\ \hline
Selection & $O(n^2)$ & $O(n^2)$ & $O(n^2)$ & $1$ & não  \\ \hline
Insertion & $O(n)$ & $O(n^2)$ & $O(n^2)$ & $1$ &  sim \\ \hline
Shellsort & $O(n)$ & $O(n^{\frac{3}{2}})$ & $O(n^{\frac{3}{2}})$ &  $1$ & não \\ \hline
\end{tabular}
\caption{Comparação dos métodos simples.}
\label{aula03:tab:caso01}
\end{table}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Métodos eficientes}

Os métodos eficientes são baseados na estratégia de {\bf divisão e conquista} (D\&C)
onde:
\begin{itemize}
\item {\bf divisão} -- divide um problema maior em problemas menores (subproblemas) 
recursivamente até que não seja mais possível dividir (caso base).

\item {\bf conquista} -- a solução dos problemas menores leva a solução do problema maior.
\end{itemize}

Diversos métodos de ordenação aplicam divisão e conquista. Os algoritmos detalhados
aqui são o \emph{quicksort} e o \emph{mergesort}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Quicksort}

Proposto em 1960 e publicado em 1962, a ideia básica é dividir o problema de
ordenar um conjunto com $n$ itens em dois problemas menores.
Os problemas menores são ordenados independentemente, e combinados para
produzir a solução final.

O Quicksort funciona da seguinte forma:
\begin{enumerate}
\item selecionar um elemento como {\bf pivô}.
\item particionar os elementos em dois subvetores:
	\begin{enumerate}
	\item elementos menores que o pivô.
	\item elementos maiores que o pivô.
	\end{enumerate}
\item executar o quicksort recursivamente em cada subvetor.
\end{enumerate}

Os passos do {\bf particionamento} são:
\begin{enumerate}
\item escolher um {\bf pivô} $pivo$.
\item percorrer o vetor a partir da esquerda até que $A[i] \geq pivo$.
\item percorrer o vetor a partir da direita até que $A[j] \leq pivo$.
\item trocar $A[i]$ com $A[j]$.
\item continuar até que $i$ e $j$ se cruzem, ou seja, enquanto $i < j$.
\end{enumerate}

O algoritmo do Quicksort é ilustrado na figura~\ref{aula03:algo:quicksort}
enquanto que o particionamento na figura~\ref{aula03:algo:partition}.
Nota-se que o pivô escolhido em cada particionamento é o número 
na primeira posição do subvetor (linha 4).
%
\begin{figure}[!htb]
\centering
\begin{framed}
\begin{lstlisting}
void Quicksort( int *A, int esq, int dir ){
	int i;
	if( esq < dir ){
		i = Partition( A, esq, dir );
		Quicksort( A, esq, i - 1 );
		Quicksort( A, i + 1, dir );
	}
}
\end{lstlisting}
\end{framed}
\caption{Algoritmo de ordenação Quicksort.}
\label{aula03:algo:quicksort}
\end{figure}

\begin{figure}[!htb]
\centering
\begin{framed}
\begin{lstlisting}
int Partition( int *A, int inicio, int fim ){
	int esq = inicio;
	int dir = fim + 1;
	int pivo = A[inicio];
	do {
		while( pivo > A[++esq] )
			if( esq == fim ) break;
		while( pivo < A[--dir] )
			if( dir == inicio ) break;
		if( esq < dir )
			troca( &A[esq], &A[dir] );
	} while( esq < dir  );
	troca( &A[inicio], &A[dir] );
	return dir;
}
\end{lstlisting}
\end{framed}
\caption{Algoritmo de partição do Quicksort.}
\label{aula03:algo:partition}
\end{figure}

A análise do Quicksort depende da {\bf escolha do pivô} para balanceamento do
particionamento, essencial na eficiencia do algoritmo.

O melhor caso do Quicksort acontece quando os dois subvetores possuem tamanho
$n/2$ e aplica-se Quicksort recursivamente.
Dado sua estrutura de árvore, a altura da árvore será $O(\log n)$ e o número
de comparações em cada nível da árvore é $O(n)$. 
Logo, o custo no {\bf melhor caso} é $O(n \log n)$.

Para o pior caso, vamos supor que o pivô é o primeiro elemento e que o vetor já esta 
ordenado.  
O particionamento resulta em subvetores de tamanho $1$ e $n-1$ onde executa-se Quicksort
em ambos recursivamente.
Dessa forma, a altura da árvore é $O(n)$ (pode-se imaginar todos os nós com 1 filho)
e comparações por nível de $O(n)$.
O custo no {\bf pior caso} será $O(n^2)$.

O problema do pior caso no Quicksort pode ser contornado ao escolher o ponto médio
de três elementos do vetor.
Por exemplo, das posições $A[0]$, $A[n/2]$ e $A[n-1]$, escolhe-se o que tem
valor médio entre eles.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Mergesort}

A ideia do Mergesort é dividir um conjunto com $n$ itens em duas partes iguais.
Os problemas menores são ordenados independentemente, e mesclados para
produzir a solução final.

O algoritmo do Mergesort é ilustrado na figura~\ref{aula03:algo:mergesort}
enquanto que a mescla na figura~\ref{aula03:algo:merge}.
%
\begin{figure}[!htb]
\centering
\begin{framed}
\begin{lstlisting}
void Mergesort( int *A, int inicio, int fim, int *aux ){
	int meio;
	if( inicio < fim ){
		meio = (inicio + fim - 1)/2;
		Mergesort( A, inicio, meio, aux );
		Mergesort( A, meio + 1, fim, aux );
		Merge( A, inicio, meio, fim, aux );
	}
}
\end{lstlisting}
\end{framed}
\caption{Algoritmo de ordenação Mergesort.}
\label{aula03:algo:mergesort}
\end{figure}

\begin{figure}[!htb]
\centering
\begin{framed}
\begin{lstlisting}
void Merge( int *A, int inicio, int meio, int fim, int *aux ){
	int i = inicio, j = meio + 1, k;
	for(k = inicio; k <= fim; k++ )
		aux[k] = A[k];
	for(k = inicio; k <= fim; k++ ){
		if(i > meio)		 A[k] = aux[j++];
		else if(j > fim)	 A[k] = aux[i++];
		else if(aux[j] < aux[i]) A[k] = aux[j++];
		else 			 A[k] = aux[i++];
	}
}
\end{lstlisting}
\end{framed}
\caption{Algoritmo para mesclar subvetores do Mergesort.}
\label{aula03:algo:merge}
\end{figure}

O algoritmo de Mergesort ilustrado {\bf não é in-place} e utiliza um vetor
temporário (ou auxiliar) para a operação de mescla.
Dessa forma, pode-se mesclar os elementos no vetor temporário e depois copiar
de volta ao vetor original.
O uso do vetor auxiliar simplifica o algoritmo, mas necessita do dobro de
espaço para fazer a ordenação.

A análise do Mergesort deve considerar que ele divide o problema em dois
subvetores de tamanho $n/2$ e aplica Mergesort recursivamente.
O custo de comparações em cada nível é $cn$ sendo o primeiro nível
$c(n/2)+c(n/2)$, o segundo $c(n/4)+c(n/4)+c(n/4)+c(n/4)$, etc.
A árvore de recursão terá $\log n + 1$ níveis, cada um com custo $cn$.
Portanto, o custo total será $cn(\log n + 1) = cn \log n + cn$.
O custo no {\bf pior caso} do algoritmo é $O(n \log n)$.

No melhor caso, o vetor de entrada já está ordenado. 
Uma forma eficiente de descobrir é testar o último elemento do primeiro subvetor
e o primeiro elemento do segundo subvetor.
As chamadas recursivas ainda são necessárias mas não será preciso fazer chamadas
ao Merge.
O custo no {\bf melhor caso} é $O(n)$.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Heapsort}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Counting sort}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Bucket sort}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Radix sort}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Classificação em memória secundária}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Exercícios}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{enumerate}
\item Ordene os elementos $3, 7, 1, 4, 9, 2$ usando os métodos: bolha, seleção,
inserção, shellsort (com gaps $3, 2, 1$). Não esqueça de exibir o estado do vetor a cada troca
de elementos.
\end{enumerate}
